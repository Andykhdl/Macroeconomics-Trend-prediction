import pandas as pd
from pandas.plotting import parallel_coordinates
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
import torch
import torch.nn as nn
import matplotlib.pyplot as plt
import seaborn as sns
from torch.utils.data import DataLoader, TensorDataset

# Loading dataset
data = pd.read_csv('DATASET.csv')
data.head()
data.info()
data.describe()

for column in data.columns:
    plt.figure(figsize=(8, 5))
    plt.plot(data[column])
    plt.title(f'{column}')
    plt.xlabel('Time')
    plt.ylabel(column)
    plt.show()

plt.figure(figsize = (15,10))
sns.heatmap(data.corr(), annot = True, annot_kws = {"size":12})

# Preprocessing
# Scaling the data
scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(data)

# Splitting data into features and target (X and y)
X = scaled_data[:, :-1]  # Features
y = scaled_data[:, -1]   # Target

# Reshape data for LSTM input [samples, time steps, features]
X = X.reshape((X.shape[0], 1, X.shape[1]))

# Convert data to PyTorch tensors
X_torch = torch.from_numpy(X).float()
y_torch = torch.from_numpy(y).float()

# Splitting the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_torch, y_torch, test_size=0.3, shuffle=False)

# Create DataLoader objects for batch processing
train_dataset = TensorDataset(X_train, y_train)
train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)

# Define the LSTM model with dropout
class LSTM(nn.Module):
    def __init__(self, input_size=8, hidden_layer_size=96, output_size=1, dropout_rate=0.4):
        super().__init__()
        self.hidden_layer_size = hidden_layer_size
        self.lstm = nn.LSTM(input_size, hidden_layer_size, dropout=dropout_rate)
        self.dropout = nn.Dropout(dropout_rate)
        self.linear = nn.Linear(hidden_layer_size, output_size)

    def forward(self, input_seq):
        # Initialize hidden state dynamically based on batch size
        batch_size = input_seq.size(1)
        hidden_cell = (torch.zeros(1, batch_size, self.hidden_layer_size).to(input_seq.device),
                        torch.zeros(1, batch_size, self.hidden_layer_size).to(input_seq.device))

        lstm_out, hidden_cell = self.lstm(input_seq, hidden_cell)
        lstm_out = self.dropout(lstm_out)
        predictions = self.linear(lstm_out.view(len(input_seq), -1))
        return predictions[-1]

model = LSTM()

# Move model to GPU if available
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)


# Define loss function and optimizer
loss_function = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.068)

# Training the model with early stopping
epochs = 600
prev_loss = float('inf')
patience = 90
counter = 0

for epoch in range(epochs):
    model.train()
    running_loss = 0.0
    for inputs, labels in train_loader:
        inputs, labels = inputs.to(device), labels.to(device)

        optimizer.zero_grad()
        model.hidden_cell = (torch.zeros(1, len(inputs), model.hidden_layer_size).to(device),
                             torch.zeros(1, len(inputs), model.hidden_layer_size).to(device))

        outputs = model(inputs)
        loss = loss_function(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()

    epoch_loss = running_loss / len(train_loader)
    print(f'Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss}')

    # Implement early stopping
    if epoch_loss < prev_loss:
        prev_loss = epoch_loss
        counter = 0
    else:
        counter += 1
        if counter >= patience:
            print("Early stopping...")
            break

# Testing the model
model.eval()
test_predictions = []

with torch.no_grad():
    for i in range(len(X_test)):
        model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_size).to(device),
                             torch.zeros(1, 1, model.hidden_layer_size).to(device))
        test_predictions.append(model(X_test[i].unsqueeze(0)).item())

# Inverse scaling to get the actual values
predicted = scaler.inverse_transform(
    np.hstack((X_test.reshape(len(X_test), X_test.shape[2]), np.array(test_predictions).reshape(len(test_predictions), 1))))
y_test_inverse = scaler.inverse_transform(
    np.hstack((X_test.reshape(len(X_test), X_test.shape[2]), y_test.reshape(len(y_test), 1))))

# Plotting the results
plt.figure(figsize=(10, 6))
plt.plot(y_test_inverse[:, -1], label='Actual GDP')
plt.plot(predicted[:, -1], label='Predicted GDP')
plt.legend()
plt.xlabel('Time (Months)')
plt.ylabel('GDP')
plt.title('GDP Prediction using LSTM with Dropout')
plt.show()

from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt

# Evaluate the model on the test set
model.eval()
test_predictions = []

with torch.no_grad():
    for i in range(len(X_test)):
        test_predictions.append(model(X_test[i].unsqueeze(1)).item())

# Reshape the test predictions and y_test to match the inverse transform input shape
test_predictions = np.array(test_predictions).reshape(-1, 1)
y_test_unscaled = y_test.detach().numpy().reshape(-1, 1)
y_test_unscaled = np.concatenate((X_test.reshape(len(X_test), -1), y_test_unscaled), axis=1)

# Inverse scaling to get the actual values
predicted_values = scaler.inverse_transform(np.concatenate((X_test.reshape(len(X_test), -1), test_predictions), axis=1))
actual_values = scaler.inverse_transform(y_test_unscaled)

# Calculate evaluation metrics
mse = mean_squared_error(actual_values[:, -1], predicted_values[:, -1])

print(f"Mean Squared Error (MSE): {mse}")
